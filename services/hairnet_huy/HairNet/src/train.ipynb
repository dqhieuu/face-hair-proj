{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ba8fcf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import logging\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7d2f231c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "96ffed5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import HairNetDataset\n",
    "from model_rewrite import HairNetModelOriginal, MyLoss, CollisionLoss, CurMSE, PosMSE, HairNetLossRewrite\n",
    "from src.train_new import HairNetLightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cdcd2cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = logging.getLogger(\"HairNet\")\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d59bb416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--epoch\", type=int, default=100)\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=32)  # 32\n",
    "    parser.add_argument(\"--lr\", type=float, default=0.0001)\n",
    "    parser.add_argument(\"--lr_step\", type=int, default=50)\n",
    "    parser.add_argument(\"--save_dir\", type=str, default=\"./weight/\")\n",
    "    parser.add_argument(\"--data\", type=str, default=\"..\")\n",
    "    parser.add_argument(\"--weight\", type=str, default=\"\")\n",
    "    parser.add_argument(\"--test_step\", type=int, default=10)\n",
    "    return parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8a92f53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, device):\n",
    "    model.train()\n",
    "    my_loss = 1e10\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        img, convdata, visweight = data\n",
    "\n",
    "        img = img.to(device)\n",
    "        convdata = convdata.to(device)\n",
    "        visweight = visweight.to(device)\n",
    "        # img (bs, 3, 128, 128); convdata (bs, 100, 4, 32, 32); visweight (bs, 100, 32, 32)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = net(img)\n",
    "        my_loss = loss(output, convdata, visweight)\n",
    "\n",
    "        my_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    return my_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3decc72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader, device):\n",
    "    pos_error = PosMSE().to(device)  # Position Loss\n",
    "    cur_error = CurMSE().to(device)  # Curvature Loss\n",
    "    col_error = CollisionLoss().to(device)  # Collision Loss\n",
    "\n",
    "    # tot_error = MyLoss().to(device)\n",
    "\n",
    "    model.eval()\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        img, convdata, visweight = data\n",
    "\n",
    "        img = img.to(device)\n",
    "        convdata = convdata.to(device)\n",
    "        visweight = visweight.to(device)\n",
    "\n",
    "        output = model(img)\n",
    "\n",
    "        # cal loss\n",
    "        pos = pos_error(output, convdata, visweight)\n",
    "        cur = cur_error(output, convdata, visweight)\n",
    "        col = col_error(output, convdata)\n",
    "\n",
    "        tot = pos + cur + col\n",
    "\n",
    "        log.info(\n",
    "            f\"TESTING Epoch {i+1} | Loss[ Pos | Cur | Col | Total ]: \"\n",
    "            f\"[ {pos:.8f} | {cur:.8f} | {col:.8f} | {tot:.8f} ]\"\n",
    "        )\n",
    "\n",
    "    # return pos.item(), cur.item(), col.item(), tot.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e6cc4b8f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:HairNet:Training args: Namespace(epoch=100, batch_size=32, lr=0.0001, lr_step=50, save_dir='./weight/', data='..', weight='', test_step=1)\n",
      "INFO:HairNet:Training device: cuda\n",
      "INFO:HairNet:Initializing model and loss function ...\n",
      "INFO:HairNet:Loading data ...\n",
      "INFO:HairNet:Train dataset: 4000 data points\n",
      "INFO:HairNet:Test dataset: 26440 data points\n",
      "INFO:HairNet:Training ...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 2. Expected size 3 but got size 1 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[56], line 63\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs): \n\u001B[0;32m     59\u001B[0m     \u001B[38;5;66;03m# measure executive time\u001B[39;00m\n\u001B[0;32m     60\u001B[0m     \u001B[38;5;66;03m# torch.cuda.synchronize()\u001B[39;00m\n\u001B[0;32m     61\u001B[0m     since \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mround\u001B[39m(time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1000\u001B[39m))\n\u001B[1;32m---> 63\u001B[0m     train_loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnet\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     64\u001B[0m     losses\u001B[38;5;241m.\u001B[39mappend(train_loss\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mdetach())\n\u001B[0;32m     66\u001B[0m     ax\u001B[38;5;241m.\u001B[39mplot(losses)\n",
      "Cell \u001B[1;32mIn[54], line 13\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, dataloader, optimizer, device)\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# img (bs, 3, 128, 128); convdata (bs, 100, 4, 32, 32); visweight (bs, 100, 32, 32)\u001B[39;00m\n\u001B[0;32m     11\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m---> 13\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mnet\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     14\u001B[0m my_loss \u001B[38;5;241m=\u001B[39m loss(output, convdata, visweight)\n\u001B[0;32m     16\u001B[0m my_loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[1;32m~\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mF:\\ai-hair-research\\hairnet_huy\\HairNet\\src\\model_rewrite.py:62\u001B[0m, in \u001B[0;36mHairNetModel.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     60\u001B[0m positions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpositionMLP(x)\n\u001B[0;32m     61\u001B[0m curvatures \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurvatureMLP(x)\n\u001B[1;32m---> 62\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mpositions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcurvatures\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Sizes of tensors must match except in dimension 2. Expected size 3 but got size 1 for tensor number 1 in the list."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # load parameters\n",
    "    opt, unknown = get_args()\n",
    "    epochs, bs, lr, lr_step, save_dir, data, weight, test_step = (\n",
    "        opt.epoch,\n",
    "        opt.batch_size,\n",
    "        opt.lr,\n",
    "        opt.lr_step,\n",
    "        opt.save_dir,\n",
    "        opt.data,\n",
    "        opt.weight,\n",
    "        opt.test_step,\n",
    "    )\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    log.info(f\"Training args: {opt}\")\n",
    "    log.info(f\"Training device: {device}\")\n",
    "\n",
    "    log.info(\"Initializing model and loss function ...\")\n",
    "\n",
    "    net = HairNetLightning(opt)\n",
    "    \n",
    "\n",
    "    #\n",
    "    # net = HairNetModelOriginal().to(device)\n",
    "    # loss = HairNetLossRewrite().to(device)\n",
    "\n",
    "    if weight != \"\":\n",
    "        log.info(\"Loading model's weight ...\")\n",
    "        net.load_state_dict(torch.load(weight, map_location=torch.device(device)))\n",
    "\n",
    "    # load data\n",
    "    log.info(\"Loading data ...\")\n",
    "    train_data = HairNetDataset(project_dir=data, train_flag=1, noise_flag=1)\n",
    "    train_loader = DataLoader(dataset=train_data, batch_size=bs)\n",
    "    log.info(f\"Train dataset: {len(train_data)} data points\")\n",
    "\n",
    "    if test_step != 0:\n",
    "        test_data = HairNetDataset(project_dir=data, train_flag=0, noise_flag=0)\n",
    "        test_loader = DataLoader(dataset=test_data, batch_size=bs)\n",
    "        log.info(f\"Test dataset: {len(test_data)} data points\")\n",
    "\n",
    "    # setup optimizer & lr schedualer\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    t = time.localtime()\n",
    "    save_path = save_dir + time.strftime(\"%Y_%m_%d_%H_%M_%S\", t)\n",
    "    os.mkdir(save_path)\n",
    "\n",
    "    # train\n",
    "    log.info(\"Training ...\")\n",
    "    pre_loss = 100000\n",
    "\n",
    "    losses = []\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "\n",
    "    for epoch in range(epochs): \n",
    "        # measure executive time\n",
    "        # torch.cuda.synchronize()\n",
    "        since = int(round(time.time() * 1000))\n",
    "\n",
    "        train_loss = train(net, train_loader, optimizer, device)\n",
    "        losses.append(train_loss.cpu().detach())\n",
    "\n",
    "        ax.plot(losses)\n",
    "        fig.canvas.draw()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # torch.cuda.synchronize()\n",
    "        time_elapsed = int(round(time.time() * 1000)) - since\n",
    "\n",
    "        # Logging\n",
    "        log.info(\n",
    "            f\"TRAINING Epoch {epoch+1} | Loss: {train_loss:.8f} | time: {time_elapsed}ms\"\n",
    "        )\n",
    "        if test_step != 0 and (epoch + 1) % test_step == 0:\n",
    "            test(net, test_loader, device)\n",
    "\n",
    "        # Save model by performance\n",
    "        if train_loss < pre_loss:\n",
    "            pre_loss = train_loss\n",
    "            torch.save(net.state_dict(), save_path + \"/weight.pt\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py:light",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
